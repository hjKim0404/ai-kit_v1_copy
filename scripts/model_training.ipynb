{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 작업환경을 현재 위치로 옮긴다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 필요한 패키지들을 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense\n",
    "from tensorflow.keras.layers import BatchNormalization, ReLU, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.datagenerator import TightFaceProvider\n",
    "from utils.helper import show_images\n",
    "from utils.helper import glob_all_files, paths2numpy, images_cropper\n",
    "from utils.helper import find_non_background, find_max_prediction, draw_rectangles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 학습용 데이터를 불러온 후 인공지능 모델 학습에 알맞게 가공해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 및 검증에 사용될 월리 책 번호\n",
    "book_number = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 사용될 이미지들의 경로를 불러온다\n",
    "fg_folder = [f'./data/book{str(book_number)}/wally/face_tight_crop',\n",
    "             f'./data/book{str(book_number)}/girlfriend/face_tight_crop',\n",
    "             f'./data/book{str(book_number)}/magician/face_tight_crop',\n",
    "             f'./data/book{str(book_number)}/fake/face_tight_crop']\n",
    "\n",
    "bg_folder = f'./data/book{str(book_number)}/common/block_imgs'\n",
    "\n",
    "tfp = TightFaceProvider(fg_folder, bg_folder, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfp가 정상적으로 생성되었는지 확인하기 위한 부분\n",
    "len(tfp)\n",
    "\n",
    "sample_imgs = tfp[0][0]\n",
    "sample_labs = tfp[0][1]\n",
    "\n",
    "show_images(sample_imgs, titles=sample_labs.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 학습 모델을 구축한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(36, 36, 3), name='inputs')\n",
    "\n",
    "conv = Conv2D(filters=32, kernel_size=3, padding='same', kernel_initializer='he_normal')(inputs)\n",
    "norm = BatchNormalization()(conv)\n",
    "relu = ReLU()(norm)\n",
    "pool = MaxPooling2D()(relu)\n",
    "\n",
    "conv = Conv2D(filters=64, kernel_size=3, padding='same', kernel_initializer='he_normal')(pool)\n",
    "norm = BatchNormalization()(conv)\n",
    "relu = ReLU()(norm)\n",
    "pool = MaxPooling2D()(relu)\n",
    "\n",
    "conv = Conv2D(filters=128, kernel_size=3, padding='same', kernel_initializer='he_normal')(pool)\n",
    "norm = BatchNormalization()(conv)\n",
    "relu = ReLU()(norm)\n",
    "pool = MaxPooling2D()(relu)\n",
    "\n",
    "flat = Flatten()(pool)\n",
    "\n",
    "#fully connected layer\n",
    "fcn = Dense(units=256, activation='relu')(flat)\n",
    "norm = BatchNormalization()(fcn)\n",
    "relu = ReLU()(norm)\n",
    "\n",
    "fcn = Dense(units=256, activation='relu')(relu)\n",
    "norm = BatchNormalization()(fcn)\n",
    "relu = ReLU()(norm)\n",
    "\n",
    "# 5가지의 카테고리를 softmax를 사용하여 분류\n",
    "pred = Dense(units=5, activation='softmax')(relu)\n",
    "\n",
    "# 모델 생성\n",
    "model = Model(inputs, pred)\n",
    "model.compile('adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모델을 학습시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습과 함께 사용될 검증 데이터를 불러오는 부분\n",
    "val_paths = [f\"./data/book{str(book_number)}/common/block_imgs_val\",\n",
    "             f\"./data/book{str(book_number)}/wally/face_val\",\n",
    "             f\"./data/book{str(book_number)}/girlfriend/face_val\",\n",
    "             f\"./data/book{str(book_number)}/magician/face_val\",\n",
    "             f\"./data/book{str(book_number)}/fake/face_val\"]\n",
    "\n",
    "paths = glob_all_files(val_paths)\n",
    "\n",
    "# 검증용 이미지들을 가져온다\n",
    "val_images = []\n",
    "path_count = 0\n",
    "\n",
    "for path in paths:\n",
    "    images = paths2numpy(path)\n",
    "\n",
    "    if not images:\n",
    "        continue\n",
    "\n",
    "    path_count += 1\n",
    "    val_images.append(images)\n",
    "\n",
    "assert path_count > 0, print(\"올바른 경로가 아니거나, 모든 경로 내에 검증용 이미지가 존재하지 않습니다.\")\n",
    "\n",
    "# 검증용 라벨들을 만든다\n",
    "val_labels = []\n",
    "for i in range(path_count):\n",
    "    val_labels.extend(np.full(len(val_images[i]), i))\n",
    "\n",
    "# list 형태의 test_images unlist 해주는 부분\n",
    "val_images = [y for x in val_images for y in x]\n",
    "\n",
    "val_images = np.array(val_images)\n",
    "val_labels = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인공지능 모델을 학습시키는 부분, history: overfitting을 체크하기 위한 변수\n",
    "history = model.fit(tfp, epochs=1, validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history['loss'])\n",
    "print(history.history['sparse_categorical_accuracy'])\n",
    "print(history.history['val_loss'])\n",
    "print(history.history['val_sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'], 'b-', label='loss')\n",
    "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['sparse_categorical_accuracy'], 'b-', label='accuracy')\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'], 'r--', label='val_accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 모델을 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"./models/book1_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 이미 저장된 모델이 있을 경우, 그 모델을 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"./models/book1_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 검증용 데이터를 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_folder = f\"./data/book{str(book_number)}/common/full_image_val\"\n",
    "imgs = glob_all_files(val_folder)\n",
    "\n",
    "assert imgs, print(\"올바른 경로가 아니거나, 경로 내에 검증용 이미지가 존재하지 않습니다.\")\n",
    "\n",
    "imgs = paths2numpy(imgs)\n",
    "\n",
    "bucket_crop_imgs, bucket_crop_crds = images_cropper(imgs, 10, 10, 36, 36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 모델을 검증용 데이터로 테스트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, img in enumerate(imgs):\n",
    "    cropped_imgs = bucket_crop_imgs[i]\n",
    "    cropped_crds = bucket_crop_crds[i]\n",
    "\n",
    "    # 예측값을 저장한 후, 그 중 0.5가 넘는 값들에 대한 불리언 마스크를 만드는 부분입니다.\n",
    "    predicts = model.predict(cropped_imgs)\n",
    "\n",
    "    # mask 를 생성하는 함수들 입니다. 둘 중에서 원하는 방식을 사용할 수 있습니다.\n",
    "    # find_non_background: 학습 모델이 이미지에서 배경이라고 판단하지 않은 부분의 인덱스들을 가져옵니다.\n",
    "    #                      limit 변수에 0이상 1미만의 값을 넣을 경우, 해당 값을 초과하는 예측값을 가진 부분의 인덱스들만을 가져옵니다.\n",
    "\n",
    "    # 두 함수 모두, target 부분에 넣는 인자에 따라 특정 캐릭터의 예측 위치를 가져올 수 있습니다.\n",
    "    # 0: 모든 캐릭터, 1: 월리, 2: 여자친구, 3: 마법사, 4: 가짜\n",
    "    mask = find_non_background(predicts, limit=0, target=0)\n",
    "\n",
    "    # show_images(cropped_imgs[bool_mask])    # 불리언 마스크를 적용시킨 결과로 얻은 월리의 얼굴로 추정되는 이미지 조각들을 출력\n",
    "    target_crds = np.array(cropped_crds)[mask]  # 찾고자 하는 캐릭터의 얼굴이 있을 것으로 예상되는 좌표들을 저장\n",
    "    predicts = predicts[mask]  # 불리언 마스크를 적용시켰을 때의 예측값을 저장\n",
    "\n",
    "    # 각 행들의 최대 예측값을 저장\n",
    "    predicts = np.max(predicts, axis=1)\n",
    "\n",
    "    # 학습 모델이 목표로 잡은 곳에 빨간 사각형을 그린 후 해당 이미지를 저장한다.\n",
    "    result_image = draw_rectangles(img, target_crds, (255, 0, 0), 3, predicts)\n",
    "\n",
    "    # 결과 이미지를 화면에 보여준다\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(result_image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, img in enumerate(imgs):\n",
    "    cropped_imgs = bucket_crop_imgs[i]\n",
    "    cropped_crds = bucket_crop_crds[i]\n",
    "\n",
    "    # 예측값을 저장한 후, 그 중 0.5가 넘는 값들에 대한 불리언 마스크를 만드는 부분입니다.\n",
    "    predicts = model.predict(cropped_imgs)\n",
    "\n",
    "    # mask 를 생성하는 함수들 입니다. 둘 중에서 원하는 방식을 사용할 수 있습니다.\n",
    "    # find_max_prediction: 학습 모델이 이미지에서 목표 캐릭터의 얼굴일 확률이 가장 높은 부분의 인덱스들을 가져옵니다.\n",
    "\n",
    "    # 두 함수 모두, target 부분에 넣는 인자에 따라 특정 캐릭터의 예측 위치를 가져올 수 있습니다.\n",
    "    # 0: 모든 캐릭터, 1: 월리, 2: 여자친구, 3: 마법사, 4: 가짜\n",
    "    mask = find_max_prediction(predicts, target=0)\n",
    "\n",
    "    # show_images(cropped_imgs[bool_mask])    # 불리언 마스크를 적용시킨 결과로 얻은 월리의 얼굴로 추정되는 이미지 조각들을 출력\n",
    "    target_crds = np.array(cropped_crds)[mask]  # 찾고자 하는 캐릭터의 얼굴이 있을 것으로 예상되는 좌표들을 저장\n",
    "    predicts = predicts[mask]  # 불리언 마스크를 적용시켰을 때의 예측값을 저장\n",
    "\n",
    "    # 각 행들의 최대 예측값을 저장\n",
    "    predicts = np.max(predicts, axis=1)\n",
    "\n",
    "    # 학습 모델이 목표로 잡은 곳에 빨간 사각형을 그린 후 해당 이미지를 저장한다.\n",
    "    result_image = draw_rectangles(img, target_crds, (255, 0, 0), 3, predicts)\n",
    "\n",
    "    # 결과 이미지를 화면에 보여준다\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(result_image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

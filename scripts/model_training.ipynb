{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 작업환경을 현재 위치로 옮긴다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 필요한 패키지들을 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense\n",
    "from tensorflow.keras.layers import BatchNormalization, ReLU, MaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.datagenerator import TightFaceProvider\n",
    "from utils.helper import show_images, glob_all_files, paths2numpy, cropper, draw_rectangles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 학습용 데이터를 불러온 후 인공지능 모델 학습에 알맞게 가공해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 및 검증에 사용될 월리 책 번호\n",
    "book_number = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 사용될 이미지들의 경로를 불러온다\n",
    "fg_folder = [f'./data/book{str(book_number)}/wally/face_tight_crop',\n",
    "             f'./data/book{str(book_number)}/girlfriend/face_tight_crop',\n",
    "             f'./data/book{str(book_number)}/magician/face_tight_crop',\n",
    "             f'./data/book{str(book_number)}/fake/face_tight_crop']\n",
    "\n",
    "bg_folder = f'./data/book{str(book_number)}/common/block_imgs'\n",
    "\n",
    "tfp = TightFaceProvider(fg_folder, bg_folder, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfp가 정상적으로 생성되었는지 확인하기 위한 부분\n",
    "len(tfp)\n",
    "\n",
    "sample_imgs = tfp[0][0]\n",
    "sample_labs = tfp[0][1]\n",
    "\n",
    "show_images(sample_imgs, titles=sample_labs.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 학습 모델을 구축한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(36, 36, 3), name='inputs')\n",
    "\n",
    "conv = Conv2D(filters=32, kernel_size=3, padding='same', kernel_initializer='he_normal')(inputs)\n",
    "norm = BatchNormalization()(conv)\n",
    "relu = ReLU()(norm)\n",
    "pool = MaxPooling2D()(relu)\n",
    "\n",
    "conv = Conv2D(filters=64, kernel_size=3, padding='same', kernel_initializer='he_normal')(pool)\n",
    "norm = BatchNormalization()(conv)\n",
    "relu = ReLU()(norm)\n",
    "pool = MaxPooling2D()(relu)\n",
    "\n",
    "conv = Conv2D(filters=128, kernel_size=3, padding='same', kernel_initializer='he_normal')(pool)\n",
    "norm = BatchNormalization()(conv)\n",
    "relu = ReLU()(norm)\n",
    "pool = MaxPooling2D()(relu)\n",
    "\n",
    "flat = Flatten()(pool)\n",
    "\n",
    "#fully connected layer\n",
    "fcn = Dense(units=256, activation='relu')(flat)\n",
    "norm = BatchNormalization()(fcn)\n",
    "relu = ReLU()(norm)\n",
    "\n",
    "fcn = Dense(units=256, activation='relu')(relu)\n",
    "norm = BatchNormalization()(fcn)\n",
    "relu = ReLU()(norm)\n",
    "\n",
    "# 5가지의 카테고리를 softmax를 사용하여 분류\n",
    "pred = Dense(units=5, activation='softmax')(relu)\n",
    "\n",
    "# 모델 생성\n",
    "model = Model(inputs, pred)\n",
    "model.compile('adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모델을 학습시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습과 함께 사용될 검증 데이터를 불러오는 부분\n",
    "test_paths = [f\"./data/book{str(book_number)}/common/validation/background/\",\n",
    "              f\"./data/book{str(book_number)}/common/validation/foreground/wally\",\n",
    "              f\"./data/book{str(book_number)}/common/validation/foreground/girlfriend\",\n",
    "              f\"./data/book{str(book_number)}/common/validation/foreground/magician\",\n",
    "              f\"./data/book{str(book_number)}/common/validation/foreground/fake\"]\n",
    "\n",
    "images = glob_all_files(test_paths)\n",
    "\n",
    "# 검증용 이미지들을 가져온다\n",
    "test_images = []\n",
    "for image in images:\n",
    "    test_images.append(paths2numpy(image))\n",
    "\n",
    "# 검증용 라벨들을 만든다\n",
    "test_labels = []\n",
    "for i in range(len(test_paths)):\n",
    "    test_labels.extend(np.full(len(test_images[i]), i))\n",
    "\n",
    "test_images = [y for x in test_images for y in x]\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인공지능 모델을 학습시키는 부분, history: overfitting을 체크하기 위한 변수\n",
    "history = model.fit(tfp, epochs=1, validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history['val_loss'])\n",
    "print(history.history['val_sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'], 'b-', label='loss')\n",
    "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['sparse_categorical_accuracy'], 'b-', label='accuracy')\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'], 'r--', label='val_accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 모델을 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"./models/book6_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 이미 저장된 모델이 있을 경우, 그 모델을 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"./models/book1_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 검증용 데이터를 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_folder = f\"./data/book{str(book_number)}/common/full_image_val\"\n",
    "imgs = glob_all_files(val_folder)\n",
    "imgs = paths2numpy(imgs)\n",
    "\n",
    "bucket_crop_imgs = []\n",
    "bucket_crop_crds = []\n",
    "\n",
    "for img in imgs:\n",
    "    \n",
    "    cropped_imgs, cropped_crds = cropper(img, 10, 10, 36, 36)\n",
    "    bucket_crop_imgs.append(cropped_imgs)\n",
    "    bucket_crop_crds.append(cropped_crds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 모델을 검증용 데이터로 테스트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 모델이 배경이 아니라고 예측한 카테고리 부분에 사각형을 그려주는 부분입니다.\n",
    "for i, img in enumerate(imgs):\n",
    "    cropped_imgs = bucket_crop_imgs[i]\n",
    "    cropped_crds = bucket_crop_crds[i]\n",
    "\n",
    "    # 예측값을 저장한 후, 그 중 0.5가 넘는 값들에 대한 불리언 마스크를 만드는 부분입니다.\n",
    "    predicts = model.predict(cropped_imgs)\n",
    "\n",
    "    # 불리언 마스크를 만들어 적용시키기 위한 부분\n",
    "    # np.argsort(predicts)[:, -1] 이후,\n",
    "    \"\"\"\n",
    "    != 0: 배경을 제외한 나머지 캐릭터들로 예측되는 곳은 true\n",
    "    == 1: 월리로 예측되는 곳만 true\n",
    "    == 2: 여자친구로 예측되는 곳만 true\n",
    "    == 3: 마법사로 예측되는 곳만 true\n",
    "    == 4: 가짜로 예측되는 곳만 true\n",
    "    \"\"\"\n",
    "    bool_mask = (np.argsort(predicts)[:, -1] != 0)\n",
    "\n",
    "    # show_images(cropped_imgs[bool_mask])    # 불리언 마스크를 적용시킨 결과로 얻은 월리의 얼굴로 추정되는 이미지 조각들을 출력\n",
    "    target_crds = np.array(cropped_crds)[bool_mask]     # 월리의 얼굴이 있을 것으로 예상되는 좌표들을 저장\n",
    "\n",
    "    predicts = predicts[bool_mask]  # 불리언 마스크를 적용시켰을 때의 예측값을 저장\n",
    "    \n",
    "    predicts = np.max(predicts, axis=1)\n",
    "\n",
    "    result_image = draw_rectangles(img, target_crds, (255, 0, 0), 3, predicts)\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(result_image)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. 모델을 검증용 데이터로 테스트합니다.\n",
    "for i, img in enumerate(imgs):\n",
    "    cropped_imgs = bucket_crop_imgs[i]\n",
    "    cropped_crds = bucket_crop_crds[i]\n",
    "\n",
    "    # 예측값을 저장한 후, 그 중 0.5가 넘는 값들에 대한 불리언 마스크를 만드는 부분입니다.\n",
    "    predicts = model.predict(cropped_imgs)\n",
    "    \n",
    "    # **test, 특정 오브젝트의 max 예측값의 인덱스를 받아와 출력하기 위한 부분\n",
    "    waly_max = np.where(predicts[:, 1] == np.max(predicts[:, 1]))\n",
    "    girl_max = np.where(predicts[:, 2] == np.max(predicts[:, 2]))\n",
    "    magi_max = np.where(predicts[:, 3] == np.max(predicts[:, 3]))\n",
    "    fake_max = np.where(predicts[:, 4] == np.max(predicts[:, 4]))\n",
    "    \n",
    "    # 모든 오브젝트의 max 예측값의 인덱스를 가져오는 부분\n",
    "    all_max = np.argsort(predicts*-1, axis=0)[0, 1:5]\n",
    "     \n",
    "    # 찾고자 하는 캐릭터의 얼굴이 있을 것으로 예상되는 좌표들을 저장\n",
    "    # [] 안에 넣는 값에 따라 찾고자 하는 캐릭터가 바뀌게 됩니다. \n",
    "    \"\"\"\n",
    "    waly_max = 월리\n",
    "    girl_max = 월리 여자친구\n",
    "    magi_max = 마법사\n",
    "    fake_max = 가짜 월리\n",
    "    all_max = 위의 모든 캐릭터들\n",
    "    \"\"\"\n",
    "    target_crds = np.array(cropped_crds)[all_max]\n",
    "    \n",
    "    predicts = predicts[all_max]  # 불리언 마스크를 적용시켰을 때의 예측값을 저장\n",
    "\n",
    "    # 각 행들의 최대 예측값을 저장\n",
    "    predicts = np.max(predicts, axis=1)\n",
    "\n",
    "    result_image = draw_rectangles(img, target_crds, (255, 0, 0), 3, predicts)\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(result_image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

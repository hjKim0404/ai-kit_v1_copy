{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 작업환경을 현재 위치로 옮긴다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 필요한 패키지들을 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense\n",
    "from tensorflow.keras.layers import BatchNormalization, ReLU, MaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.datagenerator import TightFaceProvider\n",
    "from utils.helper import glob_all_files, paths2numpy, cropper, show_images, draw_rectangles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 학습용 데이터를 불러온 후 인공지능 모델 학습에 알맞게 가공해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_folder = \"./data/wally_face_tight_crop\"\n",
    "bg_folder = \"./data/block_imgs\"\n",
    "\n",
    "tfp = TightFaceProvider(fg_folder, bg_folder, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 학습 모델을 구축한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(34, 34, 3), name='inputs')\n",
    "\n",
    "conv = Conv2D(filters=32, kernel_size=3, padding='same', kernel_initializer='he_normal')(inputs)\n",
    "norm = BatchNormalization()(conv)\n",
    "relu = ReLU()(norm)\n",
    "pool = MaxPooling2D()(relu)\n",
    "\n",
    "conv = Conv2D(filters=64, kernel_size=3, padding='same', kernel_initializer='he_normal')(pool)\n",
    "norm = BatchNormalization()(conv)\n",
    "relu = ReLU()(norm)\n",
    "pool = MaxPooling2D()(relu)\n",
    "\n",
    "conv = Conv2D(filters=128, kernel_size=3, padding='same', kernel_initializer='he_normal')(pool)\n",
    "norm = BatchNormalization()(conv)\n",
    "relu = ReLU()(norm)\n",
    "pool = MaxPooling2D()(relu)\n",
    "\n",
    "flat = Flatten()(pool)\n",
    "\n",
    "#\n",
    "fcn1 = Dense(units=256, kernel_initializer='he_normal')(flat)\n",
    "norm = BatchNormalization()(fcn1)\n",
    "relu = ReLU()(norm)\n",
    "\n",
    "#\n",
    "fcn2 = Dense(units=256, kernel_initializer='he_normal')(relu)\n",
    "norm = BatchNormalization()(fcn2)\n",
    "relu = ReLU()(norm)\n",
    "\n",
    "#\n",
    "pred = Dense(units=1, activation='sigmoid')(relu)\n",
    "\n",
    "# Model\n",
    "model = Model(inputs, pred)\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모델을 학습시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     model.fit_generator(tfp, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 모델을 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"./models/best_model2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 이미 저장된 모델이 있을 경우, 그 모델을 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"./models/new_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 검증용 데이터를 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_folder = \"./data/full_images_val\"\n",
    "images = glob_all_files(val_folder)\n",
    "images = paths2numpy(images)\n",
    "\n",
    "bucket_crop_imgs = []\n",
    "bucket_crop_crds = []\n",
    "\n",
    "for image in images:\n",
    "    cropped_imgs, cropped_crds = cropper(image, 10, 10, 34, 34)\n",
    "    bucket_crop_imgs.append(cropped_imgs)\n",
    "    bucket_crop_crds.append(cropped_crds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 모델을 검증용 데이터로 테스트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, image in enumerate(images):\n",
    "    cropped_imgs = bucket_crop_imgs[i]\n",
    "    cropped_crds = bucket_crop_crds[i]\n",
    "\n",
    "    # 예측값을 저장한 후, 그 중 0.5가 넘는 값들에 대한 불리언 마스크를 만드는 부분입니다.\n",
    "    predicts = model.predict(cropped_imgs)\n",
    "    bool_mask = (predicts > 0.5)[:, 0]\n",
    "\n",
    "    show_images(cropped_imgs[bool_mask])    # 불리언 마스크를 적용시킨 결과로 얻은 월리의 얼굴로 추정되는 이미지 조각들을 출력\n",
    "    target_crds = np.array(cropped_crds)[bool_mask]     # 월리의 얼굴이 있을 것으로 예상되는 좌표들을 저장\n",
    "\n",
    "    predicts = predicts[bool_mask]  # 불리언 마스크를 적용시켰을 때의 예측값을 저장\n",
    "    result_image = draw_rectangles(image, target_crds, (255, 0, 0), 3, predicts[:, 0])\n",
    "\n",
    "    plt.imshow(result_image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
